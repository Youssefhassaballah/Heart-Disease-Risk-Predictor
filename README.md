readme_content = """# â¤ï¸ Heart Disease Prediction Project

## ğŸ“Œ Project Overview
This project implements a **Heart Disease Prediction System** using **Machine Learning** techniques.  
The dataset used is the **Cleveland Heart Disease dataset (UCI Repository)**.  

The workflow covers **data preprocessing, feature selection, supervised & unsupervised learning, hyperparameter tuning, and deployment with Streamlit**.

---

## ğŸ“‚ Project Structure
Heart_Disease_Project/ 
â”‚â”€â”€ data/ 
â”‚   â”œâ”€â”€ heart_disease.csv 
â”‚â”€â”€ notebooks/ 
â”‚   â”œâ”€â”€ 01_data_preprocessing.ipynb 
â”‚   â”œâ”€â”€ 02_pca_analysis.ipynb 
â”‚   â”œâ”€â”€ 03_feature_selection.ipynb 
â”‚   â”œâ”€â”€ 04_supervised_learning.ipynb 
â”‚   â”œâ”€â”€ 05_unsupervised_learning.ipynb 
â”‚   â”œâ”€â”€ 06_hyperparameter_tuning.ipynb 
â”‚â”€â”€ models/ 
â”‚   â”œâ”€â”€ final_model.pkl 
â”‚â”€â”€ ui/ 
â”‚   â”œâ”€â”€ app.py (Streamlit UI) 
â”‚â”€â”€ deployment/ 
â”‚   â”œâ”€â”€ ngrok_setup.txt 
â”‚â”€â”€ results/ 
â”‚   â”œâ”€â”€ evaluation_metrics.txt 
â”‚â”€â”€ README.md 
â”‚â”€â”€ requirements.txt 
â”‚â”€â”€ .gitignore 

---

## âš™ Steps & Workflow

### **Step 1 â€“ Data Preprocessing**
- Load Cleveland dataset.  
- Handle missing values (`?` â†’ NaN â†’ imputation).  
- Encode categorical variables.  
- Save cleaned dataset as `cleaned_heart.csv`.

---

### **Step 2 â€“ Dimensionality Reduction (PCA)**
- Scale features using `StandardScaler`.  
- Apply PCA to reduce dimensionality.  
- Plot:
  - Cumulative Variance Plot.  
  - Scatter Plot (PC1 vs PC2).  
- Selected **11 PCs** explaining ~95% of variance.

---

### **Step 3 â€“ Feature Selection**
Techniques used:  
1. **Random Forest Feature Importance**  
2. **Recursive Feature Elimination (RFE)**  
3. **Chi-Square Test**

- Final selected features:
thalach, slope, ca, oldpeak, thal, cp, exang, sex
- Saved reduced dataset as `03_data_selected_features.csv`.

---

### **Step 4 â€“ Supervised Learning**
Models trained:
- Logistic Regression  
- Decision Tree  
- Random Forest  
- Support Vector Machine (SVM)  

**Evaluation Metrics:**
- Accuracy, Precision, Recall, F1-score  
- ROC Curve & AUC  

---

### **Step 5 â€“ Unsupervised Learning (Clustering)**
1. **K-Means Clustering**  
 - Elbow Method â†’ optimal K = 2  
 - Cluster scatter plots  
2. **Hierarchical Clustering**  
 - Dendrogram  
 - Agglomerative clustering  

âœ” Compared cluster assignments with actual disease labels.

---

### **Step 6 â€“ Hyperparameter Tuning**
- **Logistic Regression** â†’ GridSearchCV  
- **Random Forest** â†’ RandomizedSearchCV  

Best performance on Test Set:  
- **Random Forest (tuned):**  
- Accuracy = 90%  
- Recall = 92%  
- ROC-AUC = 0.95 âœ… (Best Model)

---

### **Step 7 â€“ Model Export**
- Saved best performing model (`RandomForestClassifier`) as:  
models/final_model.pkl

---

### **Step 8 â€“ Streamlit App**
- Developed `app.py` with **Streamlit UI**.  
- Allows user input for:
thalach, slope, ca, oldpeak, thal, cp, exang, sex
- Outputs:
- Predicted Class (High Risk / Low Risk)  
- Probability Score  

Run locally:
```bash
streamlit run app/app.py
