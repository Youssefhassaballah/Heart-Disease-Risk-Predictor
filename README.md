readme_content = """# â¤ï¸ Heart Disease Prediction Project

## ğŸ“Œ Project Overview
This project implements a **Heart Disease Prediction System** using **Machine Learning** techniques.  
The dataset used is the **Cleveland Heart Disease dataset (UCI Repository)**.  

The workflow covers **data preprocessing, feature selection, supervised & unsupervised learning, hyperparameter tuning, and deployment with Streamlit**.

---

## ğŸ“‚ Project Structure
Heart_Disease_Project/
|
â”œâ”€â”€ data/
|   â”œâ”€â”€ heart+disease                         # Original dataset
|   â”œâ”€â”€ 01_cleaned_data.csv                   # Cleaned dataset (Step 1)
|   â”œâ”€â”€ 02_data_pca.csv                       # pca dataset (Step 2)
|   â”œâ”€â”€ heart_selected_features.csv           # Reduced dataset after feature selection (Step 3)
|
â”œâ”€â”€ models/
|   â””â”€â”€ final_model.pkl              # Best trained model (Step 7)
|
â”œâ”€â”€ notebooks/
|   â”œâ”€â”€ step1_data_preprocessing.ipynb
|   â”œâ”€â”€ step2_pca_analysis.ipynb
|   â”œâ”€â”€ step3_feature_selection.ipynb
|   â”œâ”€â”€ step4_supervised_learning.ipynb
|   â”œâ”€â”€ step5_unsupervised_learning.ipynb
|   â””â”€â”€ step6_hyperparameter_tuning.ipynb
|
â”œâ”€â”€ app/
|   â””â”€â”€ app.py                       # Streamlit app for prediction (Step 9)
|
â”œâ”€â”€ results/
|   â”œâ”€â”€ evaluation_metrics.txt       # Model performance report
|   â””â”€â”€ figures/                     # Plots & visualizations
|
|â”€â”€ README.md
â””â”€â”€ Attachment.pdf


---

## âš™ Steps & Workflow

### **Step 1 â€“ Data Preprocessing**
- Load Cleveland dataset.  
- Handle missing values (`?` â†’ NaN â†’ imputation).  
- Encode categorical variables.  
- Save cleaned dataset as `01_cleaned_data.csv`.

---

### **Step 2 â€“ Dimensionality Reduction (PCA)**
- Scale features using `StandardScaler`.  
- Apply PCA to reduce dimensionality.  
- Plot:
  - Cumulative Variance Plot.  
  - Scatter Plot (PC1 vs PC2).  
- Selected **12 PCs** explaining ~95% of variance.

---

### **Step 3 â€“ Feature Selection**
Techniques used:  
1. **Random Forest Feature Importance**  
2. **Recursive Feature Elimination (RFE)**  
3. **Chi-Square Test**

- Final selected features:
thalach, slope, ca, oldpeak, thal, cp, exang, sex
- Saved reduced dataset as `03_data_selected_features.csv`.

---

### **Step 4 â€“ Supervised Learning**
Models trained:
- Logistic Regression  
- Decision Tree  
- Random Forest  
- Support Vector Machine (SVM)  

**Evaluation Metrics:**
- Accuracy, Precision, Recall, F1-score  
- ROC Curve & AUC  

---

### **Step 5 â€“ Unsupervised Learning (Clustering)**
1. **K-Means Clustering**  
 - Elbow Method â†’ optimal K = 2  
 - Cluster scatter plots  
2. **Hierarchical Clustering**  
 - Dendrogram  
 - Agglomerative clustering  

âœ” Compared cluster assignments with actual disease labels.

---

### **Step 6 â€“ Hyperparameter Tuning**
- **Logistic Regression** â†’ GridSearchCV  
- **Random Forest** â†’ RandomizedSearchCV  

Best performance on Test Set:  
- **Random Forest (tuned):**  
- Accuracy = 90%  
- Recall = 92%  
- ROC-AUC = 0.95 âœ… (Best Model)

---

### **Step 7 â€“ Model Export**
- Saved best performing model (`RandomForestClassifier`) as:  
models/final_model.pkl

---

### **Step 8 â€“ Streamlit App**
- Developed `app.py` with **Streamlit UI**.  
- Allows user input for:
thalach, slope, ca, oldpeak, thal, cp, exang, sex
- Outputs:
- Predicted Class (High Risk / Low Risk)  
- Probability Score  

Run locally:
```bash
streamlit run app/app.py
